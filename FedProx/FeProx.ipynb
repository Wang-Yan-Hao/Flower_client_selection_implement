{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1edbb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 1.13.1+cu117 and Flower 1.1.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# FedProx algorithm using package\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import copy\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb42bb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing, divide data into 10 equal parts, to simulate at most 10 clients\n",
    "NUM_CLIENTS = 10\n",
    "\n",
    "def load_datasets(num_clients: int): \n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    partition_size = len(trainset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    # Default batch_size = 32\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True)) # shuffle to random set dataset\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
    "    testloader = DataLoader(testset, batch_size=32) \n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8599bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pytorch modle for all client\n",
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # 預測function\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Get pytorch model parameter as ndarray due to flower mechanism\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "# Client train model by Client's dataset\n",
    "# net: client model\n",
    "# trainloader: client's dataset\n",
    "# epochs: the number of total epochs, decide by server\n",
    "# config: the config pass by server, include some FedProx hyperparameter\n",
    "# globol_model_ndarry: global model parameters with List[np.ndarray] type\n",
    "def train(net, trainloader, epochs: int, config, globol_model_ndarry):\n",
    "    # FedProx hyperparameter, server pass\n",
    "    gamma = config[\"gamma\"]\n",
    "    mu = config[\"mu\"]\n",
    "    learning_rate = config[\"learning_rate\"]\n",
    "    \n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss() # Client define loss function\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate) # Client define optimizer\n",
    "    net.train()\n",
    "    \n",
    "    globol_model_ndarry_copy = copy.deepcopy(globol_model_ndarry) # Copy server module parameters\n",
    "    stepLR = StepLR(optimizer, step_size=10, gamma=gamma) # Learning rate decrease(FedProx), the step_size is default to 10\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            \n",
    "            # compute FedProx proximal_term\n",
    "            proximal_term = 0.0\n",
    "            for w, w_t in zip(net.parameters(), globol_model_ndarry_copy):\n",
    "                w_t_tensor = torch.from_numpy(w_t) # globol model parameters type, from ndarrau to tensor\n",
    "                proximal_term += (w - w_t_tensor).norm(2)\n",
    "            \n",
    "            loss = criterion(net(images), labels) + (mu / 2) * proximal_term\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Evaluate Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        \n",
    "        # Evaulate\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "        \n",
    "        stepLR.step() # Learning rate decreasse\n",
    "    \n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4fc273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import Code, EvaluateIns, EvaluateRes, FitIns, FitRes, GetParametersIns, GetParametersRes, Status\n",
    "from flwr.common import ndarrays_to_parameters, parameters_to_ndarrays\n",
    "\n",
    "\n",
    "class FlowerClient(fl.client.Client):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "\n",
    "        # Get parameters as a list of NumPy ndarray's\n",
    "        ndarrays: List[np.ndarray] = get_parameters(self.net)\n",
    "\n",
    "        # Serialize ndarray's into a Parameters object\n",
    "        parameters = ndarrays_to_parameters(ndarrays)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return GetParametersRes(\n",
    "            status=status,\n",
    "            parameters=parameters,\n",
    "        )\n",
    "\n",
    "    def fit(self, ins: FitIns) -> FitRes:\n",
    "        print(f\"[Client {self.cid}] fit, config: {ins.config}\")\n",
    "        \n",
    "        # Globol model parameters\n",
    "        # Deserialize parameters to NumPy ndarray's\n",
    "        parameters_original = ins.parameters\n",
    "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
    "\n",
    "        # Update local model, train, get updated parameters\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "        train(self.net, self.trainloader, epochs=ins.config[\"locol_epochs\"], config=ins.config, globol_model_ndarry=ndarrays_original)\n",
    "        ndarrays_updated = get_parameters(self.net)\n",
    "\n",
    "        # Serialize ndarray's into a Parameters object\n",
    "        parameters_updated = ndarrays_to_parameters(ndarrays_updated)\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return FitRes(\n",
    "            status=status,\n",
    "            parameters=parameters_updated,\n",
    "            num_examples=len(self.trainloader),\n",
    "            metrics={},\n",
    "        )\n",
    "\n",
    "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {ins.config}\")\n",
    "\n",
    "        # Deserialize parameters to NumPy ndarray's\n",
    "        parameters_original = ins.parameters\n",
    "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
    "\n",
    "        set_parameters(self.net, ndarrays_original)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        # return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "        # Build and return response\n",
    "        status = Status(code=Code.OK, message=\"Success\")\n",
    "        return EvaluateRes(\n",
    "            status=status,\n",
    "            loss=float(loss),\n",
    "            num_examples=len(self.valloader),\n",
    "            metrics={\"accuracy\": float(accuracy)},\n",
    "        )\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60fec20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-12-21 21:45:10,968 | app.py:140 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2022-12-21 21:45:14,178\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "INFO flower 2022-12-21 21:45:15,384 | app.py:174 | Flower VCE: Ray initialized with resources: {'object_store_memory': 1446241075.0, 'CPU': 4.0, 'node:192.168.0.4': 1.0, 'memory': 2892482151.0}\n",
      "INFO flower 2022-12-21 21:45:15,385 | server.py:86 | Initializing global parameters\n",
      "INFO flower 2022-12-21 21:45:15,386 | server.py:270 | Requesting initial parameters from one random client\n",
      "INFO flower 2022-12-21 21:45:18,247 | server.py:274 | Received initial parameters from one random client\n",
      "INFO flower 2022-12-21 21:45:18,248 | server.py:88 | Evaluating initial parameters\n",
      "INFO flower 2022-12-21 21:45:18,249 | server.py:101 | FL starting\n",
      "DEBUG flower 2022-12-21 21:45:18,250 | server.py:215 | fit_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_get_parameters pid=40286)\u001b[0m [Client 1] get_parameters\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=40286)\u001b[0m [Client 0] fit, config: {'gamma': 0.1, 'mu': 0.01, 'learning_rate': 0.01, 'locol_epochs': 1}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=40287)\u001b[0m [Client 1] fit, config: {'gamma': 0.1, 'mu': 0.01, 'learning_rate': 0.01, 'locol_epochs': 1}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=40286)\u001b[0m Epoch 1: train loss 0.06942853331565857, accuracy 0.21666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-21 21:45:23,323 | server.py:229 | fit_round 1 received 2 results and 0 failures\n",
      "WARNING flower 2022-12-21 21:45:23,330 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-21 21:45:23,330 | server.py:165 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=40287)\u001b[0m Epoch 1: train loss 0.06889630109071732, accuracy 0.20755555555555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-21 21:45:25,522 | server.py:179 | evaluate_round 1 received 2 results and 0 failures\n",
      "WARNING flower 2022-12-21 21:45:25,522 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flower 2022-12-21 21:45:25,523 | server.py:215 | fit_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=40286)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=40287)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=40286)\u001b[0m [Client 1] fit, config: {'gamma': 0.1, 'mu': 0.01, 'learning_rate': 0.01, 'locol_epochs': 1}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=40287)\u001b[0m [Client 0] fit, config: {'gamma': 0.1, 'mu': 0.01, 'learning_rate': 0.01, 'locol_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-21 21:45:30,084 | server.py:229 | fit_round 2 received 2 results and 0 failures\n",
      "DEBUG flower 2022-12-21 21:45:30,090 | server.py:165 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=40287)\u001b[0m Epoch 1: train loss 0.06463585793972015, accuracy 0.24466666666666667\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=40286)\u001b[0m Epoch 1: train loss 0.06322526931762695, accuracy 0.27244444444444443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-21 21:45:32,737 | server.py:179 | evaluate_round 2 received 2 results and 0 failures\n",
      "DEBUG flower 2022-12-21 21:45:32,741 | server.py:215 | fit_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=40286)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=40287)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=40286)\u001b[0m [Client 1] fit, config: {'gamma': 0.1, 'mu': 0.01, 'learning_rate': 0.01, 'locol_epochs': 1}\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=40287)\u001b[0m [Client 0] fit, config: {'gamma': 0.1, 'mu': 0.01, 'learning_rate': 0.01, 'locol_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-21 21:45:37,124 | server.py:229 | fit_round 3 received 2 results and 0 failures\n",
      "DEBUG flower 2022-12-21 21:45:37,129 | server.py:165 | evaluate_round 3: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_fit pid=40286)\u001b[0m Epoch 1: train loss 0.0607190765440464, accuracy 0.30622222222222223\n",
      "\u001b[2m\u001b[36m(launch_and_fit pid=40287)\u001b[0m Epoch 1: train loss 0.06096450611948967, accuracy 0.31577777777777777\n",
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=40287)\u001b[0m [Client 1] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2022-12-21 21:45:56,285 | server.py:179 | evaluate_round 3 received 2 results and 0 failures\n",
      "INFO flower 2022-12-21 21:45:56,286 | server.py:144 | FL finished in 38.036099082000874\n",
      "INFO flower 2022-12-21 21:45:56,287 | app.py:192 | app_fit: losses_distributed [(1, 0.07017705440521241), (2, 0.06140286910533905), (3, 0.058093232035636905)]\n",
      "INFO flower 2022-12-21 21:45:56,288 | app.py:193 | app_fit: metrics_distributed {}\n",
      "INFO flower 2022-12-21 21:45:56,289 | app.py:194 | app_fit: losses_centralized []\n",
      "INFO flower 2022-12-21 21:45:56,289 | app.py:195 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(launch_and_evaluate pid=40289)\u001b[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.07017705440521241\n",
       "\tround 2: 0.06140286910533905\n",
       "\tround 3: 0.058093232035636905"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fit_config(server_round: int) -> Dict[str, str]:\n",
    "    config = {\n",
    "        \"gamma\": 0.1,\n",
    "        \"mu\": 0.01,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"locol_epochs\": 1,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "        fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "        on_fit_config_fn = fit_config,\n",
    ")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=2, # This example only simulate two clients\n",
    "    config=fl.server.ServerConfig(num_rounds=3),\n",
    "    strategy = strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e9b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
